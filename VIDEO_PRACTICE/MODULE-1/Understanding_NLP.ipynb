{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***`Understand NLP`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "import scipy\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Reading the files from current location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [file_name.split(\"\\\\\")[-1] for file_name in glob.glob(os.getcwd()+'\\\\doc*.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc1.txt', 'doc2.txt']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating the corpus from files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader(root=os.getcwd(),fileids=file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc1.txt', 'doc2.txt']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***`Courpus Paras`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['\"', 'My', 'Name', 'is', 'Rajesh', 'Sharma', '.'], ['\",', '\"', 'I', 'love', 'working', 'on', 'data', 'Science', 'projects', '.'], ['\",', '\"', 'The', 'nexon', 'car', 'is', 'very', 'affordable', '.'], ['\",', '\"', 'The', 'pizza', 'was', 'cheap', ',', 'tasty', 'and', 'delicious', '.'], ['\",', '\"', 'The', 'dominoz', 'pizza', 'is', 'tasty', 'and', 'loaded', '.\"']], [['\"', 'My', 'Name', 'is', 'Raman', 'Revti', 'Sharma', '.'], ['\",', '\"', 'I', 'love', 'doing', 'data', 'analytics', '.'], ['\",', '\"', 'The', 'tata', 'nexon', 'car', 'is', 'very', 'stylish', ',', 'dynamic', 'and', 'has', 'a', 'strong', 'build', '.'], ['But', 'their', 'after', 'sales', 'service', 'is', 'not', 'good', '.'], ['\",', '\"', 'The', 'pizza', 'in', 'the', 'party', 'was', 'tasty', 'and', 'cheesy', '.'], ['\",', '\"', 'The', 'dominoz', 'tacco', 'is', 'always', 'cripy', 'and', 'fingerlicious', '.\"']]]\n"
     ]
    }
   ],
   "source": [
    "print([para for para in corpus.paras()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***`Courpus Sentences`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"', 'My', 'Name', 'is', 'Rajesh', 'Sharma', '.'], ['\",', '\"', 'I', 'love', 'working', 'on', 'data', 'Science', 'projects', '.'], ['\",', '\"', 'The', 'nexon', 'car', 'is', 'very', 'affordable', '.'], ['\",', '\"', 'The', 'pizza', 'was', 'cheap', ',', 'tasty', 'and', 'delicious', '.'], ['\",', '\"', 'The', 'dominoz', 'pizza', 'is', 'tasty', 'and', 'loaded', '.\"'], ['\"', 'My', 'Name', 'is', 'Raman', 'Revti', 'Sharma', '.'], ['\",', '\"', 'I', 'love', 'doing', 'data', 'analytics', '.'], ['\",', '\"', 'The', 'tata', 'nexon', 'car', 'is', 'very', 'stylish', ',', 'dynamic', 'and', 'has', 'a', 'strong', 'build', '.'], ['But', 'their', 'after', 'sales', 'service', 'is', 'not', 'good', '.'], ['\",', '\"', 'The', 'pizza', 'in', 'the', 'party', 'was', 'tasty', 'and', 'cheesy', '.'], ['\",', '\"', 'The', 'dominoz', 'tacco', 'is', 'always', 'cripy', 'and', 'fingerlicious', '.\"']]\n"
     ]
    }
   ],
   "source": [
    "corpus_sents = [sent for sent in corpus.sents()]\n",
    "print(corpus_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***`Courpus Words`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'My', 'Name', 'is', 'Rajesh', 'Sharma', '.\",', '\"', 'I', 'love', 'working', 'on', 'data', 'Science', 'projects', '.\",', '\"', 'The', 'nexon', 'car', 'is', 'very', 'affordable', '.\",', '\"', 'The', 'pizza', 'was', 'cheap', ',', 'tasty', 'and', 'delicious', '.\",', '\"', 'The', 'dominoz', 'pizza', 'is', 'tasty', 'and', 'loaded', '.\"', '\"', 'My', 'Name', 'is', 'Raman', 'Revti', 'Sharma', '.\",', '\"', 'I', 'love', 'doing', 'data', 'analytics', '.\",', '\"', 'The', 'tata', 'nexon', 'car', 'is', 'very', 'stylish', ',', 'dynamic', 'and', 'has', 'a', 'strong', 'build', '.', 'But', 'their', 'after', 'sales', 'service', 'is', 'not', 'good', '.\",', '\"', 'The', 'pizza', 'in', 'the', 'party', 'was', 'tasty', 'and', 'cheesy', '.\",', '\"', 'The', 'dominoz', 'tacco', 'is', 'always', 'cripy', 'and', 'fingerlicious', '.\"']\n"
     ]
    }
   ],
   "source": [
    "corpus_words = [word for word in corpus.words()]\n",
    "print(corpus_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***`English Stopwords`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in ['not','nor','no']:\n",
    "    eng_stopwords.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(eng_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***`Cleaning the Corpus`***\n",
    "- ##### **Removing special characters**\n",
    "- ##### **Removing unwanted spaces**\n",
    "- ##### **Lower case the words**\n",
    "- ##### **Tokenizing the words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"', 'My', 'Name', 'is', 'Rajesh', 'Sharma', '.'], ['\",', '\"', 'I', 'love', 'working', 'on', 'data', 'Science', 'projects', '.'], ['\",', '\"', 'The', 'nexon', 'car', 'is', 'very', 'affordable', '.'], ['\",', '\"', 'The', 'pizza', 'was', 'cheap', ',', 'tasty', 'and', 'delicious', '.'], ['\",', '\"', 'The', 'dominoz', 'pizza', 'is', 'tasty', 'and', 'loaded', '.\"'], ['\"', 'My', 'Name', 'is', 'Raman', 'Revti', 'Sharma', '.'], ['\",', '\"', 'I', 'love', 'doing', 'data', 'analytics', '.'], ['\",', '\"', 'The', 'tata', 'nexon', 'car', 'is', 'very', 'stylish', ',', 'dynamic', 'and', 'has', 'a', 'strong', 'build', '.'], ['But', 'their', 'after', 'sales', 'service', 'is', 'not', 'good', '.'], ['\",', '\"', 'The', 'pizza', 'in', 'the', 'party', 'was', 'tasty', 'and', 'cheesy', '.'], ['\",', '\"', 'The', 'dominoz', 'tacco', 'is', 'always', 'cripy', 'and', 'fingerlicious', '.\"']]\n"
     ]
    }
   ],
   "source": [
    "print(corpus_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['my name is rajesh sharma'], ['i love working on data science projects'], ['the nexon car is very affordable'], ['the pizza was cheap tasty and delicious'], ['the dominoz pizza is tasty and loaded'], ['my name is raman revti sharma'], ['i love doing data analytics'], ['the tata nexon car is very stylish dynamic and has a strong build'], ['but their after sales service is not good'], ['the pizza in the party was tasty and cheesy'], ['the dominoz tacco is always cripy and fingerlicious']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_sent = []\n",
    "for sent in corpus_sents:\n",
    "    process_sent = [re.sub('[^A-Za-z]+', ' ', str(sent)).strip().lower()]\n",
    "    cleaned_sent.append(process_sent)\n",
    "    \n",
    "print(cleaned_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***`Removing Stopwords`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_sents = []\n",
    "\n",
    "for sent in cleaned_sent:\n",
    "    sent_words = []\n",
    "    for word in re.sub('[^A-Za-z]+', ' ',str(sent)).strip().split(\" \"):\n",
    "        if word not in eng_stopwords:\n",
    "            sent_words.append(word)\n",
    "    preprocess_sents.append(sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['name', 'rajesh', 'sharma'], ['love', 'working', 'data', 'science', 'projects'], ['nexon', 'car', 'affordable'], ['pizza', 'cheap', 'tasty', 'delicious'], ['dominoz', 'pizza', 'tasty', 'loaded'], ['name', 'raman', 'revti', 'sharma'], ['love', 'data', 'analytics'], ['tata', 'nexon', 'car', 'stylish', 'dynamic', 'strong', 'build'], ['sales', 'service', 'not', 'good'], ['pizza', 'party', 'tasty', 'cheesy'], ['dominoz', 'tacco', 'always', 'cripy', 'fingerlicious']]\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***`Featurization`***\n",
    "### **1. BAG of WORDS (BOW)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-284-9e3ef17cf7e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBOW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_sents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "BOW = cv.fit_transform([' '.join(preprocess_sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x35 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 35 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cv.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affordable', 'always', 'analytics', 'build', 'car', 'cheap', 'cheesy', 'cripy', 'data', 'delicious', 'dominoz', 'dynamic', 'fingerlicious', 'good', 'loaded', 'love', 'name', 'nexon', 'not', 'party', 'pizza', 'projects', 'rajesh', 'raman', 'revti', 'sales', 'science', 'service', 'sharma', 'strong', 'stylish', 'tacco', 'tasty', 'tata', 'working']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_stop_words())       ## Here, in countvectoriser we can also initialize the stopwords but in this case I have kept it blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affordable</th>\n",
       "      <th>always</th>\n",
       "      <th>analytics</th>\n",
       "      <th>build</th>\n",
       "      <th>car</th>\n",
       "      <th>cheap</th>\n",
       "      <th>cheesy</th>\n",
       "      <th>cripy</th>\n",
       "      <th>data</th>\n",
       "      <th>delicious</th>\n",
       "      <th>dominoz</th>\n",
       "      <th>dynamic</th>\n",
       "      <th>fingerlicious</th>\n",
       "      <th>good</th>\n",
       "      <th>loaded</th>\n",
       "      <th>love</th>\n",
       "      <th>name</th>\n",
       "      <th>nexon</th>\n",
       "      <th>not</th>\n",
       "      <th>party</th>\n",
       "      <th>pizza</th>\n",
       "      <th>projects</th>\n",
       "      <th>rajesh</th>\n",
       "      <th>raman</th>\n",
       "      <th>revti</th>\n",
       "      <th>sales</th>\n",
       "      <th>science</th>\n",
       "      <th>service</th>\n",
       "      <th>sharma</th>\n",
       "      <th>strong</th>\n",
       "      <th>stylish</th>\n",
       "      <th>tacco</th>\n",
       "      <th>tasty</th>\n",
       "      <th>tata</th>\n",
       "      <th>working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   affordable  always  analytics  build  car  cheap  cheesy  cripy  data  \\\n",
       "0           1       1          1      1    2      1       1      1     2   \n",
       "\n",
       "   delicious  dominoz  dynamic  fingerlicious  good  loaded  love  name  \\\n",
       "0          1        2        1              1     1       1     2     2   \n",
       "\n",
       "   nexon  not  party  pizza  projects  rajesh  raman  revti  sales  science  \\\n",
       "0      2    1      1      3         1       1      1      1      1        1   \n",
       "\n",
       "   service  sharma  strong  stylish  tacco  tasty  tata  working  \n",
       "0        1       2       1        1      1      3     1        1  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_features = pd.DataFrame(BOW.toarray(),columns=cv.get_feature_names())\n",
    "bow_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. N-grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name rajesh sharma love working data science projects nexon car affordable pizza cheap tasty delicious dominoz pizza tasty loaded name raman revti sharma love data analytics tata nexon car stylish dynamic strong build sales service not good pizza party tasty cheesy dominoz tacco always cripy fingerlicious']\n"
     ]
    }
   ],
   "source": [
    "print([' '.join(final_corpus_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = cv2.fit_transform([' '.join(final_corpus_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1,\n",
       "        3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1,\n",
       "        1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affordable',\n",
       " 'affordable pizza',\n",
       " 'always',\n",
       " 'always cripy',\n",
       " 'analytics',\n",
       " 'analytics tata',\n",
       " 'build',\n",
       " 'build sales',\n",
       " 'car',\n",
       " 'car affordable',\n",
       " 'car stylish',\n",
       " 'cheap',\n",
       " 'cheap tasty',\n",
       " 'cheesy',\n",
       " 'cheesy dominoz',\n",
       " 'cripy',\n",
       " 'cripy fingerlicious',\n",
       " 'data',\n",
       " 'data analytics',\n",
       " 'data science',\n",
       " 'delicious',\n",
       " 'delicious dominoz',\n",
       " 'dominoz',\n",
       " 'dominoz pizza',\n",
       " 'dominoz tacco',\n",
       " 'dynamic',\n",
       " 'dynamic strong',\n",
       " 'fingerlicious',\n",
       " 'good',\n",
       " 'good pizza',\n",
       " 'loaded',\n",
       " 'loaded name',\n",
       " 'love',\n",
       " 'love data',\n",
       " 'love working',\n",
       " 'name',\n",
       " 'name rajesh',\n",
       " 'name raman',\n",
       " 'nexon',\n",
       " 'nexon car',\n",
       " 'not',\n",
       " 'not good',\n",
       " 'party',\n",
       " 'party tasty',\n",
       " 'pizza',\n",
       " 'pizza cheap',\n",
       " 'pizza party',\n",
       " 'pizza tasty',\n",
       " 'projects',\n",
       " 'projects nexon',\n",
       " 'rajesh',\n",
       " 'rajesh sharma',\n",
       " 'raman',\n",
       " 'raman revti',\n",
       " 'revti',\n",
       " 'revti sharma',\n",
       " 'sales',\n",
       " 'sales service',\n",
       " 'science',\n",
       " 'science projects',\n",
       " 'service',\n",
       " 'service not',\n",
       " 'sharma',\n",
       " 'sharma love',\n",
       " 'strong',\n",
       " 'strong build',\n",
       " 'stylish',\n",
       " 'stylish dynamic',\n",
       " 'tacco',\n",
       " 'tacco always',\n",
       " 'tasty',\n",
       " 'tasty cheesy',\n",
       " 'tasty delicious',\n",
       " 'tasty loaded',\n",
       " 'tata',\n",
       " 'tata nexon',\n",
       " 'working',\n",
       " 'working data']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affordable</th>\n",
       "      <th>affordable pizza</th>\n",
       "      <th>always</th>\n",
       "      <th>always cripy</th>\n",
       "      <th>analytics</th>\n",
       "      <th>analytics tata</th>\n",
       "      <th>build</th>\n",
       "      <th>build sales</th>\n",
       "      <th>car</th>\n",
       "      <th>car affordable</th>\n",
       "      <th>car stylish</th>\n",
       "      <th>cheap</th>\n",
       "      <th>cheap tasty</th>\n",
       "      <th>cheesy</th>\n",
       "      <th>cheesy dominoz</th>\n",
       "      <th>cripy</th>\n",
       "      <th>cripy fingerlicious</th>\n",
       "      <th>data</th>\n",
       "      <th>data analytics</th>\n",
       "      <th>data science</th>\n",
       "      <th>delicious</th>\n",
       "      <th>delicious dominoz</th>\n",
       "      <th>dominoz</th>\n",
       "      <th>dominoz pizza</th>\n",
       "      <th>dominoz tacco</th>\n",
       "      <th>dynamic</th>\n",
       "      <th>dynamic strong</th>\n",
       "      <th>fingerlicious</th>\n",
       "      <th>good</th>\n",
       "      <th>good pizza</th>\n",
       "      <th>loaded</th>\n",
       "      <th>loaded name</th>\n",
       "      <th>love</th>\n",
       "      <th>love data</th>\n",
       "      <th>love working</th>\n",
       "      <th>name</th>\n",
       "      <th>name rajesh</th>\n",
       "      <th>name raman</th>\n",
       "      <th>nexon</th>\n",
       "      <th>nexon car</th>\n",
       "      <th>not</th>\n",
       "      <th>not good</th>\n",
       "      <th>party</th>\n",
       "      <th>party tasty</th>\n",
       "      <th>pizza</th>\n",
       "      <th>pizza cheap</th>\n",
       "      <th>pizza party</th>\n",
       "      <th>pizza tasty</th>\n",
       "      <th>projects</th>\n",
       "      <th>projects nexon</th>\n",
       "      <th>rajesh</th>\n",
       "      <th>rajesh sharma</th>\n",
       "      <th>raman</th>\n",
       "      <th>raman revti</th>\n",
       "      <th>revti</th>\n",
       "      <th>revti sharma</th>\n",
       "      <th>sales</th>\n",
       "      <th>sales service</th>\n",
       "      <th>science</th>\n",
       "      <th>science projects</th>\n",
       "      <th>service</th>\n",
       "      <th>service not</th>\n",
       "      <th>sharma</th>\n",
       "      <th>sharma love</th>\n",
       "      <th>strong</th>\n",
       "      <th>strong build</th>\n",
       "      <th>stylish</th>\n",
       "      <th>stylish dynamic</th>\n",
       "      <th>tacco</th>\n",
       "      <th>tacco always</th>\n",
       "      <th>tasty</th>\n",
       "      <th>tasty cheesy</th>\n",
       "      <th>tasty delicious</th>\n",
       "      <th>tasty loaded</th>\n",
       "      <th>tata</th>\n",
       "      <th>tata nexon</th>\n",
       "      <th>working</th>\n",
       "      <th>working data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   affordable  affordable pizza  always  always cripy  analytics  \\\n",
       "0           1                 1       1             1          1   \n",
       "\n",
       "   analytics tata  build  build sales  car  car affordable  car stylish  \\\n",
       "0               1      1            1    2               1            1   \n",
       "\n",
       "   cheap  cheap tasty  cheesy  cheesy dominoz  cripy  cripy fingerlicious  \\\n",
       "0      1            1       1               1      1                    1   \n",
       "\n",
       "   data  data analytics  data science  delicious  delicious dominoz  dominoz  \\\n",
       "0     2               1             1          1                  1        2   \n",
       "\n",
       "   dominoz pizza  dominoz tacco  dynamic  dynamic strong  fingerlicious  good  \\\n",
       "0              1              1        1               1              1     1   \n",
       "\n",
       "   good pizza  loaded  loaded name  love  love data  love working  name  \\\n",
       "0           1       1            1     2          1             1     2   \n",
       "\n",
       "   name rajesh  name raman  nexon  nexon car  not  not good  party  \\\n",
       "0            1           1      2          2    1         1      1   \n",
       "\n",
       "   party tasty  pizza  pizza cheap  pizza party  pizza tasty  projects  \\\n",
       "0            1      3            1            1            1         1   \n",
       "\n",
       "   projects nexon  rajesh  rajesh sharma  raman  raman revti  revti  \\\n",
       "0               1       1              1      1            1      1   \n",
       "\n",
       "   revti sharma  sales  sales service  science  science projects  service  \\\n",
       "0             1      1              1        1                 1        1   \n",
       "\n",
       "   service not  sharma  sharma love  strong  strong build  stylish  \\\n",
       "0            1       2            2       1             1        1   \n",
       "\n",
       "   stylish dynamic  tacco  tacco always  tasty  tasty cheesy  tasty delicious  \\\n",
       "0                1      1             1      3             1                1   \n",
       "\n",
       "   tasty loaded  tata  tata nexon  working  working data  \n",
       "0             1     1           1        1             1  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_features = pd.DataFrame(ngrams.toarray(),columns=cv2.get_feature_names())\n",
    "ngrams_features.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
